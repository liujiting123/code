{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ],
   "id": "ab5e0eaaa2828888"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def vgg16(batch_norm=False) -> nn.ModuleList:\n",
    "    \"\"\" 创建 vgg16 模型\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    batch_norm: bool\n",
    "        是否在卷积层后面添加批归一化层\n",
    "    \"\"\"\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    cfg = [64, 64, 'M', 128, 128, 'M', 256, 256,\n",
    "           256, 'C', 512, 512, 512, 'M', 512, 512, 512]\n",
    "\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers.append(nn.MaxPool2d(2, 2))\n",
    "        elif v == 'C':\n",
    "            layers.append(nn.MaxPool2d(2, 2, ceil_mode=True))\n",
    "        else:\n",
    "            conv = nn.Conv2d(in_channels, v, 3, padding=1)\n",
    "\n",
    "            # 如果需要批归一化的操作就添加一个批归一化层\n",
    "            if batch_norm:\n",
    "                layers.extend([conv, nn.BatchNorm2d(v), nn.ReLU(True)])\n",
    "            else:\n",
    "                layers.extend([conv, nn.ReLU(True)])\n",
    "\n",
    "            in_channels = v\n",
    "\n",
    "    # 将原始的 fc6、fc7 全连接层替换为卷积层\n",
    "    layers.extend([\n",
    "        nn.MaxPool2d(3, 1, 1),\n",
    "        nn.Conv2d(512, 1024, 3, padding=6, dilation=6),  # conv6 使用空洞卷积增加感受野\n",
    "        nn.ReLU(True),\n",
    "        nn.Conv2d(1024, 1024, 1),  # conv7\n",
    "        nn.ReLU(True)\n",
    "    ])\n",
    "\n",
    "    layers = nn.ModuleList(layers)\n",
    "    return layers\n",
    "\n",
    "\n",
    "#生成锚框\n",
    "# coding:utf-8\n",
    "from itertools import product\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "class PriorBox:\n",
    "    \"\"\" 用来生成先验框的类 \"\"\"\n",
    "\n",
    "    def __init__(self, image_size=300, feature_maps: list = None, min_sizes: list = None,\n",
    "                 max_sizes: list = None, aspect_ratios: list = None, steps: list = None, **kwargs):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        image_size: int\n",
    "            图像大小\n",
    "\n",
    "        feature_maps: list\n",
    "            特征图大小\n",
    "\n",
    "        min_sizes: list\n",
    "            特征图中的最小正方形先验框的尺寸\n",
    "\n",
    "        max_sizes: list\n",
    "            下一个特征图中的最小正方形先验框的尺寸\n",
    "\n",
    "        aspect_ratios: list\n",
    "            长宽比\n",
    "\n",
    "        steps: list\n",
    "            步长，可理解为感受野大小\n",
    "        \"\"\"\n",
    "        self.image_size = image_size\n",
    "        self.feature_maps = feature_maps or [38, 19, 10, 5, 3, 1]\n",
    "        self.min_sizes = min_sizes or [30, 60, 111, 162, 213, 264]\n",
    "        self.max_sizes = max_sizes or [60, 111, 162, 213, 264, 315]\n",
    "        self.steps = steps or [8, 16, 32, 64, 100, 300]\n",
    "        self.aspect_ratios = aspect_ratios or [\n",
    "            [2], [2, 3], [2, 3], [2, 3], [2], [2]]\n",
    "\n",
    "    def __call__(self):\n",
    "        \"\"\" 得到所有先验框\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        boxes: Tensor of shape (n_priors, 4)\n",
    "            先验框\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "\n",
    "        for k, f in enumerate(self.feature_maps):\n",
    "            f_k = self.image_size / self.steps[k]\n",
    "\n",
    "            for i, j in product(range(f), repeat=2):\n",
    "                # 中心坐标，向右为 x 轴正方向，向下为 y 轴正方向\n",
    "                cx = (j + 0.5) / f_k\n",
    "                cy = (i + 0.5) / f_k\n",
    "\n",
    "                # 1 和 1'\n",
    "                s_k = self.min_sizes[k] / self.image_size\n",
    "                s_k_prime = sqrt(s_k * self.max_sizes[k] / self.image_size)\n",
    "\n",
    "                boxes.append([cx, cy, s_k, s_k])\n",
    "                boxes.append([cx, cy, s_k_prime, s_k_prime])\n",
    "\n",
    "                # 根据其余的 ar 计算宽和高\n",
    "                for ar in self.aspect_ratios[k]:\n",
    "                    boxes.append([cx, cy, s_k * sqrt(ar), s_k / sqrt(ar)])\n",
    "                    boxes.append([cx, cy, s_k / sqrt(ar), s_k * sqrt(ar)])\n",
    "\n",
    "        boxes = torch.Tensor(boxes).clamp(min=0, max=1)\n",
    "        return boxes\n",
    "\n",
    "\n",
    "#L2标准化\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "class L2Norm(nn.Module):\n",
    "    \"\"\" L2 标准化 \"\"\"\n",
    "\n",
    "    def __init__(self, n_channels: int, scale=20):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_channels: int\n",
    "            通道数\n",
    "\n",
    "        scale: float\n",
    "            l2标准化的缩放比\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.gamma = scale\n",
    "        self.eps = 1e-10\n",
    "        self.n_channels = n_channels\n",
    "        self.weight = nn.Parameter(Tensor(self.n_channels))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.constant_(self.weight, self.gamma)\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        norm = x.pow(2).sum(dim=1, keepdim=True).sqrt() + self.eps\n",
    "        x = torch.div(x, norm)\n",
    "        # 将 weight 的维度变为 [1, n_channels, 1, 1]\n",
    "        y = x * self.weight[None, ..., None, None]\n",
    "        return y\n",
    "\n",
    "\n",
    "#SSD类的实现\n",
    "\n",
    "\n",
    "class SSD(nn.Module):\n",
    "    \"\"\" SSD 神经网络模型 \"\"\"\n",
    "\n",
    "    def __init__(self, n_classes: int, variance=(0.1, 0.2), top_k=200, conf_thresh=0.01,\n",
    "                 nms_thresh=0.45, image_size=300, **config):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_classes: int\n",
    "            要预测的种类数，包括背景\n",
    "\n",
    "        variance: Tuple[float, float]\n",
    "            先验框的方差\n",
    "\n",
    "        top_k: int\n",
    "            每个类的边界框上限\n",
    "\n",
    "        conf_thresh: float\n",
    "            置信度阈值\n",
    "\n",
    "        nms_thresh: float\n",
    "            nms 中 IOU 阈值\n",
    "\n",
    "        image_size: int\n",
    "            图像尺寸\n",
    "\n",
    "        **config:\n",
    "            关于先验框生成的配置\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        if len(variance) != 2:\n",
    "            raise ValueError(\"variance 只能有 2 元素\")\n",
    "\n",
    "        self.n_classes = n_classes\n",
    "        self.image_size = image_size\n",
    "        config['image_size'] = image_size\n",
    "\n",
    "        # 生成先验框\n",
    "        self.priorbox_generator = PriorBox(**config)\n",
    "        self.prior = Tensor(self.priorbox_generator())\n",
    "\n",
    "        # 各个模块\n",
    "        self.vgg = vgg16()\n",
    "        self.l2norm = L2Norm(512, 20)\n",
    "        self.extras = nn.ModuleList([\n",
    "            nn.Conv2d(1024, 256, 1),  # conv8_2\n",
    "            nn.Conv2d(256, 512, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(512, 128, 1),  # conv9_2\n",
    "            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n",
    "            nn.Conv2d(256, 128, 1),  # conv10_2\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "            nn.Conv2d(256, 128, 1),  # conv11_2\n",
    "            nn.Conv2d(128, 256, 3),\n",
    "        ])\n",
    "        self.confs = nn.ModuleList([\n",
    "            nn.Conv2d(512, n_classes * 4, 3, padding=1),\n",
    "            nn.Conv2d(1024, n_classes * 6, 3, padding=1),\n",
    "            nn.Conv2d(512, n_classes * 6, 3, padding=1),\n",
    "            nn.Conv2d(256, n_classes * 6, 3, padding=1),\n",
    "            nn.Conv2d(256, n_classes * 4, 3, padding=1),\n",
    "            nn.Conv2d(256, n_classes * 4, 3, padding=1),\n",
    "        ])\n",
    "        self.locs = nn.ModuleList([\n",
    "            nn.Conv2d(512, 4 * 4, 3, padding=1),\n",
    "            nn.Conv2d(1024, 4 * 6, 3, padding=1),\n",
    "            nn.Conv2d(512, 4 * 6, 3, padding=1),\n",
    "            nn.Conv2d(256, 4 * 6, 3, padding=1),\n",
    "            nn.Conv2d(256, 4 * 4, 3, padding=1),\n",
    "            nn.Conv2d(256, 4 * 4, 3, padding=1),\n",
    "        ])\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: Tensor of shape (N, 3, H, W)\n",
    "            图像数据\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        loc: Tensor of shape (N, n_priors, 4)\n",
    "            偏移量\n",
    "\n",
    "        conf: Tensor of shape (N, n_priors, n_classes)\n",
    "            类别置信度\n",
    "\n",
    "        prior: Tensor of shape (n_priors, 4)\n",
    "            先验框\n",
    "        \"\"\"\n",
    "        loc = []\n",
    "        conf = []\n",
    "        sources = []\n",
    "\n",
    "        # 批大小\n",
    "        N = x.size(0)\n",
    "\n",
    "        # 计算从 conv4_3 输出的特征图\n",
    "        for layer in self.vgg[:23]:\n",
    "            x = layer(x)\n",
    "\n",
    "        # 保存 conv4_3 输出的 l2 标准化结果\n",
    "        sources.append(self.l2norm(x))\n",
    "\n",
    "        # 计算 vgg16 后面几个卷积层的特征图\n",
    "        for layer in self.vgg[23:]:\n",
    "            x = layer(x)\n",
    "\n",
    "        # 保存 conv7 的输出的特征图\n",
    "        sources.append(x)\n",
    "\n",
    "        # 计算后面几个卷积层输出的特征图\n",
    "        for i, layer in enumerate(self.extras):\n",
    "            x = self.relu(layer(x))\n",
    "            if i % 2 == 1:\n",
    "                sources.append(x)\n",
    "\n",
    "        # 使用分类器和探测器进行预测并将通道变为最后一个维度方便堆叠\n",
    "        for x, conf_layer, loc_layer in zip(sources, self.confs, self.locs):\n",
    "            loc.append(loc_layer(x).permute(0, 2, 3, 1).contiguous())\n",
    "            conf.append(conf_layer(x).permute(0, 2, 3, 1).contiguous())\n",
    "\n",
    "        # 输出维度为 (batch_size, n_priors, n_classes) 和 (batch_size, n_priors, 4)\n",
    "        conf = torch.cat([i.view(N, -1) for i in conf], dim=1)\n",
    "        loc = torch.cat([i.view(N, -1) for i in loc], dim=1)\n",
    "\n",
    "        return loc.view(N, -1, 4), conf.view(N, -1, self.n_classes), self.prior"
   ],
   "id": "b526fdee237688c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MultiBoxLoss(nn.Module):\n",
    "    def __init__(self, priors, overlap_thresh=0.5, neg_pos_ratio=3, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        - priors: Tensor, 预定义的先验框\n",
    "        - overlap_thresh: float, 正样本和真实框之间的最小 IoU 阈值\n",
    "        - neg_pos_ratio: int, 正负样本比例\n",
    "        - alpha: float, 用于平衡分类损失和回归损失的权重\n",
    "        \"\"\"\n",
    "        super(MultiBoxLoss, self).__init__()\n",
    "        self.priors = priors  # 先验框\n",
    "        self.overlap_thresh = overlap_thresh  # IoU 阈值\n",
    "        self.neg_pos_ratio = neg_pos_ratio  # 正负样本比例\n",
    "        self.alpha = alpha  # 回归损失的权重\n",
    "\n",
    "        self.cross_entropy = nn.CrossEntropyLoss(reduction='sum')  # 分类损失\n",
    "        self.smooth_l1 = nn.SmoothL1Loss(reduction='sum')  # 回归损失\n",
    "\n",
    "    def forward(self, loc_preds, conf_preds, priors, targets):\n",
    "        \"\"\"\n",
    "        计算多任务损失，包括分类损失和回归损失\n",
    "\n",
    "        Parameters:\n",
    "        - loc_preds: Tensor, 预测的边界框坐标 (batch_size, num_priors, 4)\n",
    "        - conf_preds: Tensor, 预测的类别概率 (batch_size, num_priors, num_classes)\n",
    "        - priors: Tensor, 预定义的先验框 (num_priors, 4)\n",
    "        - targets: Tensor, 真实框和类别标签 (batch_size, num_objects, 5)\n",
    "        \"\"\"\n",
    "\n",
    "        # Step 1: 计算每个先验框与真实框之间的 IoU\n",
    "        iou_matrix = self.calculate_iou(priors, targets)\n",
    "\n",
    "        # Step 2: 将先验框与真实框进行匹配（正样本和负样本）\n",
    "        # 每个先验框的分类标签和回归目标\n",
    "        conf_labels, loc_targets = self.match_priors_with_gt(iou_matrix, targets)\n",
    "\n",
    "        # Step 3: 计算分类损失\n",
    "        conf_loss = self.cross_entropy(conf_preds.view(-1, conf_preds.size(2)), conf_labels.view(-1))\n",
    "\n",
    "        # Step 4: 计算回归损失\n",
    "        loc_loss = self.smooth_l1(loc_preds.view(-1, 4), loc_targets.view(-1, 4))\n",
    "\n",
    "        # 总损失 = 分类损失 + 回归损失\n",
    "        total_loss = conf_loss + self.alpha * loc_loss\n",
    "        return total_loss\n",
    "\n",
    "    def calculate_iou(self, priors, targets):\n",
    "        \"\"\"计算每个先验框和真实框之间的IoU\"\"\"\n",
    "        return torchvision.ops.box_iou(priors, targets)\n",
    "\n",
    "\n",
    "    def match_priors_with_gt(self, iou_matrix, targets):\n",
    "        \"\"\"\n",
    "        匹配每个先验框与真实框，并返回正负样本标签及回归目标\n",
    "        \"\"\"\n",
    "        # 根据 IoU 确定哪些先验框是正样本，哪些是负样本\n",
    "        conf_labels = torch.zeros(iou_matrix.size(0), dtype=torch.long)  # 默认为背景（负样本）\n",
    "        loc_targets = torch.zeros_like(self.priors)  # 初始化回归目标\n",
    "\n",
    "        # 找出每个先验框的最佳匹配（IoU 最大的真实框）\n",
    "        best_iou, best_idx = iou_matrix.max(1)\n",
    "\n",
    "        # 选择 IoU 大于阈值的先验框作为正样本\n",
    "        pos_mask = best_iou > self.overlap_thresh\n",
    "        conf_labels[pos_mask] = targets[best_idx[pos_mask], 0]  # 根据匹配的真实框的类别填充标签\n",
    "\n",
    "        # 计算正样本的回归目标\n",
    "        loc_targets[pos_mask] = targets[best_idx[pos_mask], 1:]  # 真实框的坐标\n",
    "\n",
    "        # 负样本：IoU 小于阈值的先验框\n",
    "        neg_mask = best_iou < 0.4  # 设置负样本的 IoU 阈值\n",
    "        conf_labels[neg_mask] = 0  # 标记负样本为背景（类别 0）\n",
    "\n",
    "        return conf_labels, loc_targets"
   ],
   "id": "d26f723fe49b619e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
