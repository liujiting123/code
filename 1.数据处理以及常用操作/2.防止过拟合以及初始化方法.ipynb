{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "权重衰退",
   "id": "7011c303019f0c8f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc = nn.Linear(10, 1)  # 一个简单的全连接层\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "model = SimpleModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9,weight_decay=5e-4)\n",
    "optimizer_2 = optim.SGD([\n",
    "    {'params': model.fc.weight, 'weight_decay': 0.01},  # 权重参数\n",
    "    {'params': model.fc.bias, 'weight_decay': 0}        # 偏置参数\n",
    "], lr=0.01)\n",
    "\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "权重初始化",
   "id": "4c0c35624e1635bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "model.apply(init_weights)\n",
    "\n",
    "#常见的参数初始化方法\n",
    "param =0  #随便定义的，跑不了的\n",
    "# 全零初始化\n",
    "nn.init.constant_(param, 0)\n",
    "\n",
    "# 全一初始化\n",
    "nn.init.constant_(param, 1)\n",
    "\n",
    "# 均匀分布初始化\n",
    "nn.init.uniform_(param, a=-0.1, b=0.1)\n",
    "\n",
    "# 正态分布初始化\n",
    "nn.init.normal_(param, mean=0, std=0.01)\n",
    "\n",
    "# Xavier 均匀分布，适用于sigmoid函数或者tanh函数作为激活函数的网络\n",
    "nn.init.xavier_uniform_(param)\n",
    "\n",
    "# Xavier 正态分布，适用于sigmoid函数或者tanh函数作为激活函数的网络\n",
    "nn.init.xavier_normal_(param)\n",
    "\n",
    "# Kaiming 均匀分布，适用于ReLu作为激活函数的网络以及深层网络\n",
    "nn.init.kaiming_uniform_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "# Kaiming 正态分布，适用于ReLu作为激活函数的网络以及深层网络\n",
    "nn.init.kaiming_normal_(param, mode='fan_in', nonlinearity='relu')\n",
    "\n",
    "#正交初始化，适用于自注意力机制\n",
    "nn.init.orthogonal_(param, gain=1.0)\n",
    "\n",
    "#查看层中有什么参数的方法\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"name: {name}, param: {param}\")\n",
    "\n",
    "# 查看所有子层\n",
    "for name, layer in model.named_modules():\n",
    "    print(f\"Layer name: {name}, Layer type: {type(layer)}\")\n",
    "\n",
    "# 查看直接子层\n",
    "for name, layer in model.named_children():\n",
    "    print(f\"Layer name: {name}, Layer type: {type(layer)}\")"
   ],
   "id": "a6c259bbb22e413"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "丢弃法",
   "id": "37eaaf6c23745ee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet,self).__init__()\n",
    "        self.fc1 = nn.Linear(10,5)\n",
    "        self.fc2 = nn.Linear(5,3)\n",
    "        self.fc3 = nn.Linear(3,1)\n",
    "        self.dropout_1 = nn.Dropout(0.2)\n",
    "        self.dropout_2 = nn.Dropout(0.2)\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout_1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.dropout_2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n"
   ],
   "id": "bd24624e8ed250e5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
